from pandas import read_csv, DataFrame
from sklearn.model_selection import train_test_split
from os.path import join
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score


seed = 42
dataPath = r"D:\Project\Sem7\DataPrepared\data0Prepared.csv"

# Meta-heuristic constants 
eph = 1e3
earlyStop = 10
N = 10


def splitData(features, label):
    global xTrain, xTest, yTrain, yTest, xVal, yVal
    xTrain, xTest, yTrain, yTest = train_test_split(features, label, test_size=0.3, random_state=seed)
    xTrain, xVal, yTrain, yVal = train_test_split(xTrain, yTrain, test_size=0.3, random_state=seed)


def showMetrics(yPred, modelName):
    yPred = [ele > 0.50 for ele in yPred]
    print(modelName)
    acc = round(accuracy_score(yTest, yPred), 4)
    prsc = round(precision_score(yTest, yPred), 4)
    rcll = round(recall_score(yTest, yPred), 4)
    f1 = round(f1_score(yTest, yPred), 4)
    roc = round(roc_auc_score(yTest, yPred), 4)
    print('Confusion Matrix:\n', confusion_matrix(yTest, yPred))
    print('Accuracy Score:', acc)
    print('Precision Score:', prsc)
    print('Recall Score:', rcll)
    print('F1 Score:', f1)
    print('ROC AUC score:', roc)
    return (acc, prsc, rcll, f1, roc)


# Lower and Upper bound
#      0,    1,   2,     3,   4,    5,    6,   7,   8,    9,  10
lb = [ 0,    0, 2.5, -1.99,   0,    1, 5e-3, 180, 1e3,    1,  -1]
ub = [ 2, 0.99, 3.5,    -1, 0.5, 1.99, 5e-2, 220, 1e5, 1.99,  -1]
# 
# Default Values

# Encoders
kernel = { 0: 'linear', 1: 'poly', 2: 'rbf', 3: 'sigmoid', 4: 'precomputed' }
gamma = { 0: 'scale', 1: 'auto'}
decisionFunction = { 0: 'ovo', 1: 'ovr'}


def makeHyperparameters(sol):
    # print(sol)
    C = sol[0]
    krnEnc = int(sol[1])
    krn = kernel[krnEnc]
    degree = int(sol[2])
    gma = sol[3]
    if gma < 0:
        gmaEnc = abs(int(gma))
        gma = gamma[gmaEnc]
    coef = sol[4]
    shrnking = bool(int(sol[5]))
    tol = sol[6]
    cache = int(sol[7])
    maxIter = int(sol[8])
    decFuncEnc = int(sol[9])
    decFunc = decisionFunction[decFuncEnc]
    rndState = sol[10]
    if rndState < 0:
        rndState = None
    else:
        rndState = int(rndState)
    params = {
        'C': C,
        'kernel': krn,
        'degree': degree,
        'gamma': gma,
        'coef0': coef,
        'shrinking': shrnking,
        'tol': tol,
        'cache_size': cache,
        'max_iter': maxIter,
        'decision_function_shape': decFunc,
        'random_state': rndState,
    }
    return params


def fitness(sol):
    hyperparameters = makeHyperparameters(sol)
    try:
        regg = SVC(**hyperparameters)
        regg.fit(X=xTrain, y=yTrain)
    except:
        return 0
    else:
        yP = regg.predict(X=xVal)
        roc = roc_auc_score(yVal, yP)
        return roc
        # r2 = mt.r2_score(yVal, yP)
        # return r2
    

def metaheuristicHypertune(optm):
    '''Hypertuning of parameters of Support Vector Classification'''

    prb = {
        'fit_func': fitness,
        'lb': lb,
        'ub': ub,
        'minmax': 'max'
    }
    trmn = {
        'max_early_stop': earlyStop
    }

    try:    
        sol, bestFit = optm.solve(problem=prb, termination=trmn)
        # print('Solution:\n', sol)
        #Best model evaluation
        bestHyperparameters = makeHyperparameters(sol)
        bestModel = SVC(**bestHyperparameters)
        bestModel.fit(X=xTrain, y=yTrain)
    except Exception as e:
        bestHyperparameters = e
        metrics = (0, 0, 0, 0, 0)
        bestFit = 0
    else:         
        yPred = bestModel.predict(X=xTest)
        metrics = showMetrics(yPred, 'Support Vector Classifier Optimised')
        print('Best Fit:\n', bestFit)

    return bestHyperparameters, metrics, bestFit



def bayesOpt(C, kernel, degree, gamma, coef0, shrinking, tol, cache_size, max_iter, 
             decision_function_shape, random_state):

    sol = [C, kernel, degree, gamma, coef0, shrinking, tol, cache_size, max_iter, 
             decision_function_shape, random_state]
    params = makeHyperparameters(sol)

    model = SVC(**params)
    try:
        model.fit(xTrain, yTrain)
    except:
        return 0
    
    pred = model.predict(xVal)
    try:
        return roc_auc_score(yVal, pred)
    except:
        return 0


def bayesOptimisation(nIter=10):
    from bayes_opt import BayesianOptimization
    params = {
        'C': (lb[0], ub[0]),
        'kernel': (lb[1], ub[1]),
        'degree': (lb[2], ub[2]),
        'gamma': (lb[3], ub[3]),
        'coef0': (lb[4], ub[4]),
        'shrinking': (lb[5], ub[5]),
        'tol': (lb[6], ub[6]),
        'cache_size': (lb[7], ub[7]),
        'max_iter': (lb[8], ub[8]),
        'decision_function_shape': (lb[9], ub[9]),
        'random_state': (lb[10], ub[10]),
    }

    optimise = BayesianOptimization(bayesOpt, params, random_state=seed)
    optimise.maximize(n_iter=nIter, init_points=10)

    bestParams = optimise.max['params']
    C = bestParams['C']
    kernel = bestParams['kernel']
    degree = bestParams['degree']
    gamma = bestParams['gamma']
    coef0 =  bestParams['coef0']
    shrinking = bestParams['shrinking']
    tol = bestParams['tol']
    cache_size = bestParams['cache_size']
    max_iter = bestParams['max_iter']
    decision_function_shape = bestParams['decision_function_shape']
    random_state = bestParams['random_state']
    sol = [C, kernel, degree, gamma, coef0, shrinking, tol, cache_size, max_iter, 
             decision_function_shape, random_state]
    bestParams = makeHyperparameters(sol)

    print(bestParams)
    regg = SVC(**bestParams)
    try:
        regg.fit(xTrain, yTrain)
        yPred = regg.predict(xTest)
        metrics = showMetrics(yPred, 'SVC Optimised by Bayes Optimisation')
    except:
        metrics = (0, 0, 0, 0, 0)
    return bestParams, metrics


def PowerSet(s, n): 
    '''Function to print the power set'''
    def findPowerSet(s, res, n): 
        if (n == 0): 
            temp = []
            for i in res: 
                temp.append(i) 
            columnsPowerSet.append(temp)
            return
    
        # append the subset to result 
        res.append(s[n - 1]) 
        findPowerSet(s, res, n - 1) 
        res.pop() 
        findPowerSet(s, res, n - 1) 

    ans = [] 
    findPowerSet(s, ans, n)


def columnInclusion(optName='BayesOpt'):
    '''Hyper tuning by including columns'''

    Column = ['Latitude', 'Longitude', 'TWI', 'TPI', 'Slope', 'Rainfall', 'Hillshade', 'Elevation', 'DrainageDensity', 
              'ProfileCurvature', 'PlanCurvature', 'Curvature', 'Aspect', 'Soil', 'LULC']
    
    dfFileName = f'columnInclusionFeatsSelect{optName}SVC.csv'
    dfPath = join(r"D:\Project\Sem7\Python\reportFiles", dfFileName)
    columnsPowerSet = []
    PowerSet(Column[:], len(Column[:]))
    columnsPowerSet.pop()
    for i in reversed(range(0, len(columnsPowerSet))):
        data = read_csv(dataPath)
        try:
            columnsPowerSet[i].remove('Soil')
            columnsPowerSet[i] += ['Soil3639', 'Soil3662', 'Soil3691', 'Soil3717', 'Soil3761', 'Soil3849', 'Soil3850', 'Soil6998']
        except:
            pass
        try: 
            columnsPowerSet[i].remove('LULC')
            columnsPowerSet[i] += ['LULC1', 'LULC2', 'LULC5', 'LULC7', 'LULC8', 'LULC9', 'LULC10', 'LULC11']
        except:
            pass
        try:
            df = read_csv(dfPath)
        except:
            df = DataFrame(columns=['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc', 'includedColumns', 'params', ])
        print('Included columns:\n', columnsPowerSet[i])
        features = data.loc[:, columnsPowerSet[i]]
        label = data.iloc[:, -1]
        splitData(features, label)

        if optName.lower()[0] == 'b':
            params, metrics = bayesOptimisation()
            df.loc[i, 'includedColumns'] = str(columnsPowerSet[i])
            df.loc[i, 'params'] = str(params)
            df.loc[i, 'accuracy'] = metrics[0]
            df.loc[i, 'precision'] = metrics[1]
            df.loc[i, 'recall'] = metrics[2]
            df.loc[i, 'f1_score'] = metrics[3]
            df.loc[i, 'roc_auc'] = metrics[4]
        elif optName.lower()[0] == 'm':
            from metaHeuristicOptimizers import getOptimizersDictionary
            dictOpt = getOptimizersDictionary(epochs=eph, population=N)
            for k in range(0, len(dictOpt.keys())):
                print('\n\nHeuristic k: ', k)
                key = list(dictOpt.keys())[k]
                params, metrics, bestFit = metaheuristicHypertune(dictOpt[key])
                df.loc[i, 'includedColumns'] = str(columnsPowerSet[i])
                df.loc[i, 'meteHeuristic'] = str(key)
                df.loc[i, 'params'] = str(params)
                df.loc[i, 'accuracy'] = metrics[0]
                df.loc[i, 'precision'] = metrics[1]
                df.loc[i, 'recall'] = metrics[2]
                df.loc[i, 'f1_score'] = metrics[3]
                df.loc[i, 'roc_auc'] = metrics[4]
                df.loc[i, 'bestFit'] = bestFit

        df.to_csv(dfPath, index=False)


def columnExclusion(optName='BayesOpt'):
    '''Hyper tuning by removing columns'''

    Column = ['Latitude', 'Longitude', 'TWI', 'TPI', 'Slope', 'Rainfall', 'Hillshade', 'Elevation', 'DrainageDensity', 
              'ProfileCurvature', 'PlanCurvature', 'Curvature', 'Aspect', 'Soil', 'LULC']
    
    Column.remove('Latitude')
    dfFileName = f'columnExclusionFeatsSelect{optName}SVC.csv'
    dfPath = join(r"D:\Project\Sem7\Python\reportFiles", dfFileName)
    for item in Column:
        data = read_csv(dataPath)
        clm = [item, ] + ['Latitude']
        try:
            df = read_csv(dfPath)
            i = len(df)
        except:
            df = DataFrame(columns=['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc', 'excludedColumns', 'params', ])
            i = 0
        if item == 'LULC':
            clm = ['Latitude'] + ['LULC1', 'LULC2', 'LULC5', 'LULC7', 'LULC8', 'LULC9', 'LULC10', 'LULC11']
        if item == 'Soil':
            clm = ['Latitude'] + ['Soil3639', 'Soil3662', 'Soil3691', 'Soil3717', 'Soil3761', 'Soil3849', 'Soil3850', 'Soil6998']
        data = data.drop(clm, axis=1)
        features = data.iloc[:, :-1]
        label = data.iloc[:, -1]
        splitData(features, label)

        if optName.lower()[0] == 'b':
            print('Excluded columns: \n', clm)
            params, metrics = bayesOptimisation()
            df.loc[i, 'excludedColumns'] = str(clm)
            df.loc[i, 'params'] = str(params)
            df.loc[i, 'accuracy'] = metrics[0]
            df.loc[i, 'precision'] = metrics[1]
            df.loc[i, 'recall'] = metrics[2]
            df.loc[i, 'f1_score'] = metrics[3]
            df.loc[i, 'roc_auc'] = metrics[4]
            df.to_csv(dfPath, index=False)
            i += 1
        elif optName.lower()[0] == 'm':
            from metaHeuristicOptimizers import getOptimizersDictionary
            dictOpt = getOptimizersDictionary(epochs=eph, population=N)
            for k in range(0, len(dictOpt.keys())):
                print('\n\nHeuristic k: ', k)
                print('Excluded columns: \n', clm)
                key = list(dictOpt.keys())[k]
                params, metrics, bestFit = metaheuristicHypertune(dictOpt[key])
                df.loc[i, 'excludedColumns'] = str(clm)
                df.loc[i, 'meteHeuristic'] = str(key)
                df.loc[i, 'params'] = str(params)
                df.loc[i, 'accuracy'] = metrics[0]
                df.loc[i, 'precision'] = metrics[1]
                df.loc[i, 'recall'] = metrics[2]
                df.loc[i, 'f1_score'] = metrics[3]
                df.loc[i, 'roc_auc'] = metrics[4]
                df.loc[i, 'bestFit'] = bestFit
                df.to_csv(dfPath, index=False)
                i += 1
        


def normalSVC(optType='bayes'):
    '''Normal check of Support Vector Classification'''

    data = read_csv(dataPath)
    features = data.iloc[:, :-1]
    label = data.iloc[:, -1]
    splitData(features, label)

    if optType == 'bayes':
        params, metrics = bayesOptimisation(nIter=40)
    elif optType == 'metaheuristic':
        params, metrics = metaheuristicHypertune()

    print('Optimised Parameters: \n', params)



if __name__ == '__main__':
    import time
    t0 = time.time()
    global columnsPowerSet 

    
    # normalSVC('metaheuristic')
    columnExclusion('MetaHeuristic')



    t1 = time.time()
    t = time.strftime('%H:%M:%S', time.gmtime(t1-t0))
    print('Total time taken: ', t)